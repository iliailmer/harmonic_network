{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3X5PzdFuSqI6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edZfWmO2gKEE"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import Parameter\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor, Compose, RandomRotation, ToPILImage\n",
    "torch.cuda.is_available()\n",
    "torch.random.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTmPPe_HLZDD"
   },
   "outputs": [],
   "source": [
    "tfms = Compose([ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "OWccGX9pgKEM",
    "outputId": "158b2f78-c94a-4888-a3c7-2aac4deba5c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10('./', \n",
    "                   download=True, \n",
    "                   train=True,\n",
    "                   transform=tfms)\n",
    "testset = CIFAR10('./', \n",
    "                  train=False,\n",
    "                  transform=tfms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          # sampler=train_sampler,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         # sampler=test_sampler,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=0)\n",
    "\n",
    "from skimage.exposure import rescale_intensity\n",
    "import numpy as np\n",
    "from scipy import fftpack\n",
    "from scipy.ndimage import maximum_filter, minimum_filter\n",
    "from torch import Tensor, uint8\n",
    "\n",
    "\n",
    "def rescale(image: np.ndarray, mn: int = 0, mx: int = 1):\n",
    "    return rescale_intensity(image, out_range=(mn, mx))\n",
    "\n",
    "\n",
    "def rescale_torch(image: Tensor) -> Tensor:\n",
    "    return (255 * (image - image.min()) / (image.max() - image.min())).type(uint8)\n",
    "\n",
    "\n",
    "def rot90(matrix: Tensor) -> Tensor:\n",
    "    dims = range(len(matrix.shape))\n",
    "    return matrix.transpose(dims[-2], dims[-1]).flip(2)\n",
    "\n",
    "\n",
    "def weight_rotate_(weight: np.array, rot: int = 0) -> np.array:\n",
    "    if rot % 4 == 0:\n",
    "        return weight\n",
    "    if rot % 4 == 1:\n",
    "        return np.rot90(weight)\n",
    "    if rot % 4 == 2:\n",
    "        return np.rot90(np.rot90(weight))\n",
    "    if rot % 4 == 3:\n",
    "        return np.rot90(np.rot90(np.rot90(weight)))\n",
    "\n",
    "def weight_rotate(weight: Tensor, rot: int = 0) -> Tensor:\n",
    "    if rot % 4 == 0:\n",
    "        return weight\n",
    "    if rot % 4 == 1:\n",
    "        return rot90(weight)\n",
    "    if rot % 4 == 2:\n",
    "        return rot90(rot90(weight))\n",
    "    if rot % 4 == 3:\n",
    "        return rot90(rot90(rot90(weight)))\n",
    "\n",
    "\n",
    "def edges(image: np.ndarray,\n",
    "          size: int = 3) -> np.ndarray:\n",
    "    image = rescale(image)\n",
    "    ratio = np.zeros_like(image)\n",
    "    if len(image.shape) > 2:\n",
    "        ratio = np.divide(maximum_filter(image, (size, size, size)) + 1,\n",
    "                          minimum_filter(image, (size, size, size)) + 1)\n",
    "    else:\n",
    "        ratio = np.divide(maximum_filter(image, (size, size)) + 1,\n",
    "                          minimum_filter(image, (size, size)) + 1)\n",
    "    ratio = rescale(20 * np.log(ratio))\n",
    "    return ratio\n",
    "\n",
    "\n",
    "def add_edges(image: np.ndarray, a: float = 0.5, b: float = 0.5,\n",
    "              size: int = 3) -> np.ndarray:\n",
    "    ratio = np.zeros_like(image)\n",
    "    if len(image.shape) > 2:\n",
    "        ratio = np.divide(maximum_filter(image, (size, size, size)) + 1,\n",
    "                          minimum_filter(image, (size, size, size)) + 1)\n",
    "    else:\n",
    "        ratio = np.divide(maximum_filter(image, (size, size)) + 1,\n",
    "                          minimum_filter(image, (size, size)) + 1)\n",
    "    ratio = rescale(20 * np.log(ratio))\n",
    "    image = rescale(image)\n",
    "    return (a * image + b * ratio) / (a + b)\n",
    "\n",
    "\n",
    "def EME(image):\n",
    "    return np.sum(edges(image)) / image.size\n",
    "\n",
    "\n",
    "def alpha_rooting_fourier(image: np.ndarray, alpha: float = 0.9) -> np.array:\n",
    "    ffted = fftpack.fft2(image)\n",
    "    abs_ffted = np.absolute(ffted) ** alpha\n",
    "    iffted = fftpack.ifft2(abs_ffted * np.divide(ffted, np.absolute(ffted),\n",
    "                                                 out=np.zeros_like(ffted),\n",
    "                                                 where=np.absolute(ffted) != 0))\n",
    "    iffted = rescale(np.absolute(iffted), 0, 1)  # .astype(int)\n",
    "    return iffted\n",
    "\n",
    "\n",
    "def calc_output_shape(in_shape, kernel, stride, pad):\n",
    "    w, h = in_shape\n",
    "    w_ = (w - kernel + 2 * pad) / stride + 1\n",
    "    h_ = (h - kernel + 2 * pad) / stride + 1\n",
    "    return int(w_), int(h_)\n",
    "\n",
    "\n",
    "def train_1_batch(model):\n",
    "    model.train()\n",
    "    _, (data, label) = list(enumerate(trainloader))[0]\n",
    "\n",
    "    data, label = torch.autograd.Variable(data).cuda(), torch.autograd.Variable(label).cuda()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    # label_ = one_hot_enc(output, label, 7)\n",
    "    loss = criterion(output, label)\n",
    "    y_pred = torch.max(output, 1)[1]\n",
    "    print(\"Output:\", output)\n",
    "    print(\"Loss on 1 batch:\", loss.data.item())\n",
    "    print(\"Accuracy on 1 batch:\", y_pred.eq(label.data).cpu().sum())\n",
    "    print(\"predictions:\", y_pred.data)\n",
    "    print(\"truth:\", label.data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def train_portion(model, epoch, step, portion=20):\n",
    "    model.train()\n",
    "    assert isinstance(portion, int)\n",
    "    for batch_id, (data, label) in enumerate(trainloader):\n",
    "        if batch_id < portion:\n",
    "            data, label = torch.autograd.Variable(data).cuda(), torch.autograd.Variable(label).cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            label_ = one_hot_enc(output, label, 10)\n",
    "            loss = criterion(output, label_)\n",
    "            y_pred = torch.max(output, 1)[1]\n",
    "            # print(\"Output:\", output)\n",
    "            if epoch % step == 0:\n",
    "                print(f\"Epoch {epoch}, training loss on 1 batch:\", loss.data.item())\n",
    "            train_losses.append(loss.data.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def test_portion(model, epoch, step, portion=20):\n",
    "    model.eval()\n",
    "    assert isinstance(portion, int)\n",
    "    with torch.no_grad():\n",
    "        for batch_id, (data, label) in enumerate(testloader):\n",
    "            if batch_id < portion:\n",
    "                data, label = torch.autograd.Variable(data).cuda(), torch.autograd.Variable(label).cuda()\n",
    "                output = model(data)\n",
    "                label_ = one_hot_enc(output, label, 10)\n",
    "                loss = criterion(output, label_)\n",
    "                y_pred = torch.max(output, 1)[1]\n",
    "                test_losses.append(loss.data.item())\n",
    "                # print(\"Output:\", output)\n",
    "                if epoch % step == 0:\n",
    "                    print(f\"Epoch {epoch}, testing loss on 1 batch:\", loss.data.item())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fsOzXMj0MQ10"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class HarmonicBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_ch,\n",
    "                 bn=True,\n",
    "                 dropout=False,\n",
    "                 kernel_size=3,\n",
    "                 lmbda=None,\n",
    "                 diag=False, \n",
    "                 pad=1, \n",
    "                 stride=1,\n",
    "                 bias = False):\n",
    "        super(HarmonicBlock, self).__init__()\n",
    "        \"\"\"\n",
    "        :param input_channels: number of channels in the input\n",
    "        :param kernel_size: size of the kernel in the filter bank\n",
    "        :param pad: padding size\n",
    "        :param stride: stride size\n",
    "        :param lmbda: number of filters to be actually used (feature not implemented)\n",
    "        \"\"\"\n",
    "        self.bn = bn\n",
    "        self.drop = dropout\n",
    "        self.input_channels = input_channels\n",
    "        self.output_ch = output_ch\n",
    "        self.pad = pad\n",
    "        self.stride = stride\n",
    "        self.K = kernel_size\n",
    "        self.diag = diag\n",
    "        self.N = self.K  # preferably to have N=K !! (to fully replicate the paper), this is the convolution window size\n",
    "        self.PI = torch.as_tensor(np.pi)\n",
    "        if lmbda is not None:\n",
    "            if lmbda > self.K ** 2:\n",
    "                self.lmbda = self.K ** 2  # limits the number of kernels\n",
    "            else:\n",
    "                self.lmbda = lmbda\n",
    "        else:\n",
    "            self.lmbda = lmbda\n",
    "        self.diag = diag  # flag to select diagonal entries of the block\n",
    "        self.filter_bank = self.get_filter_bank(N=self.N,\n",
    "                                                K=self.K,  # kernel size\n",
    "                                                input_channels=self.input_channels,\n",
    "                                                lmbda=self.lmbda,\n",
    "                                                diag=self.diag).to('cuda')\n",
    "        self.conv = nn.Conv2d(in_channels=self.filter_bank.shape[0], out_channels=self.output_ch,\n",
    "                              kernel_size=1,\n",
    "                              padding=0,\n",
    "                              stride=1, bias=bias)\n",
    "        \n",
    "        if self.bn:\n",
    "            self.bnorm = nn.BatchNorm2d(self.filter_bank.shape[0])\n",
    "        if self.drop:\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "    def fltr(self, u, v, N, k):\n",
    "        return torch.as_tensor([[torch.cos(torch.as_tensor(self.PI / N * (ii + 0.5) * v)) * torch.cos(\n",
    "            torch.as_tensor(self.PI / N * (jj + 0.5) * u)) for ii in range(k)] for jj in range(k)])\n",
    "\n",
    "\n",
    "    def get_idx(self, K, l):\n",
    "        out = []\n",
    "        for i in range(K):\n",
    "            for j in range(K):\n",
    "                if i + j < l:\n",
    "                    out.append(K * i + j)\n",
    "        return tuple(out)\n",
    "\n",
    "    def get_idx_diag(self, K):\n",
    "        out = []\n",
    "        for i in range(K):\n",
    "            for j in range(K):\n",
    "                if i == j:\n",
    "                    out.append(i + j)\n",
    "        return tuple(out)\n",
    "\n",
    "    def draw_filters(self, fb_):\n",
    "        fig, ax = plt.subplots(len(fb_), 1, figsize=(12, 4))\n",
    "        j = 0\n",
    "        for i in range(len(fb_)):\n",
    "            ax[i].imshow(fb_[i, 0, :, :])\n",
    "            ax[i].axis('off')\n",
    "            ax[i].grid(False)\n",
    "\n",
    "    def get_filter_bank(self, N, K, input_channels=3, lmbda=None, diag=False):\n",
    "        filter_bank = torch.zeros((K, K, K, K))\n",
    "        for i in range(K):\n",
    "            for j in range(K):\n",
    "                filter_bank[i, j, :, :] = self.fltr(i, j, N, K)\n",
    "        if lmbda is not None:\n",
    "            ids = self.get_idx(K, lmbda)\n",
    "            return torch.stack(tuple([filter_bank.view(-1, 1, K, K)] * input_channels), dim=1).view(\n",
    "                (-1, input_channels, K, K))[ids, :, :, :].view(-1,1,K,K)  # filter_bank.view(K**2,-1,K,K)\n",
    "        if diag:\n",
    "            ids = self.get_idx_diag(K)\n",
    "            return torch.stack(tuple([filter_bank.view(-1, 1, K, K)] * input_channels), dim=1).view(\n",
    "                (-1, input_channels, K, K))[ids, :, :, :].view(-1,1,K,K)   # filter_bank.view(K**2,-1,K,K)[ids,:,:,:]\n",
    "        return torch.stack(tuple([filter_bank.view(-1, 1, K, K)] * input_channels), dim=1).view(\n",
    "            (-1, 1, K, K))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.conv2d(x.to(torch.float32),\n",
    "                     weight=self.filter_bank.to(torch.float32),\n",
    "                     padding=self.pad,\n",
    "                     stride=self.stride,\n",
    "                     groups=self.input_channels)  # int(self.K/2)\n",
    "        if self.bn:\n",
    "            x = self.bnorm(x)\n",
    "        if self.drop:\n",
    "            x = self.dropout(x)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = HarmonicBlock(input_channels=5, output_ch=3,kernel_size=5).cuda()\n",
    "x=torch.from_numpy(np.random.randn(1,5,32,32)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 30, 30])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideHarmonicResNet(nn.Module):\n",
    "    def __init__(self, in_channels, depth, num_classes=10, widen_factor=1, lmbda=None, diag=False ):\n",
    "        super(WideHarmonicResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) // 6\n",
    "        block = HarmonicBlock\n",
    "        self.lmbda=lmbda\n",
    "        self.diag=diag\n",
    "        self.conv1 = HarmonicBlock(input_channels=3, output_ch=nChannels[0],\n",
    "                                   kernel_size=3, \n",
    "                                   stride=1,\n",
    "                                   pad=1, bias=False)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        \n",
    "        self.stack1 = self._make_layer(block, \n",
    "                                       nb_layers=n, \n",
    "                                       in_planes=nChannels[0],\n",
    "                                       out_planes=nChannels[1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride=1,\n",
    "                                       pad=1)\n",
    "        self.stack2 = self._make_layer(block, \n",
    "                                       nb_layers=n, \n",
    "                                       in_planes=nChannels[1],\n",
    "                                       out_planes=nChannels[2],\n",
    "                                       kernel_size=3,\n",
    "                                       stride=2,\n",
    "                                       pad=1)\n",
    "        self.stack3 = self._make_layer(block, \n",
    "                                       nb_layers=n, \n",
    "                                       in_planes=nChannels[2],\n",
    "                                       out_planes=nChannels[3],\n",
    "                                       kernel_size=3,\n",
    "                                       stride=2,\n",
    "                                       pad=1)\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "        \n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, kernel_size, pad):\n",
    "        strides = [stride] +[1]*(nb_layers-1)\n",
    "        stacking = []\n",
    "        for st in strides:\n",
    "            stacking.append(block(input_channels=in_planes,\n",
    "                                  lmbda=self.lmbda,\n",
    "                                  diag=self.diag,\n",
    "                                  output_ch=out_planes,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  stride=st,\n",
    "                                  pad=pad))\n",
    "            if in_planes!=out_planes:\n",
    "                in_planes=out_planes\n",
    "        return nn.Sequential(*stacking)\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.drop(out)\n",
    "        out = self.stack1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.stack2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.stack3(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        return self.fc(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = WideHarmonicResNet(3,28,widen_factor=10).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      " Epoch: 0, learning rate = 1.0e-02;\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2195b23116374e379194e0c0a9593ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy = 14.00%;\n",
      "             F1 = 8.24%;             Precision = 9.79%;             Recall = 14.52%             Loss: 2.20e+00\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e8faf224ca4c7cb56c329946e49caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=79), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Saving model ...\n",
      "\n",
      "\n",
      "Testing accuracy = 16.00%; \n",
      "             F1 = 9.53%;             Precision = 13.16%;            Recall = 16.95%             Loss: 2.14e+00\n",
      "\n",
      " Epoch: 1, learning rate = 1.0e-02;\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446fd4bc56e74717807bb15dd12a94d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-295-08c8bb9038d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" Epoch: {epoch}, learning rate = {lr:1.1e};\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-295-08c8bb9038d5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mcorrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         f1 += f1_score(y_true=label.data.cpu().numpy(),\n\u001b[1;32m    127\u001b[0m                        \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "# , classification_report, confusion_matrix\n",
    "from torchvision.transforms import ToTensor\n",
    "from models.model_harmonic import HarmonicNet\n",
    "# from local_loader import LocalLoader\n",
    "from loader import LoaderSmall\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from typing import List  # pylint: ignore\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "\n",
    "tfms = None  # Compose(transforms=[RandomRotate90(p=0.4), Rotate(p=0.5)])\n",
    "\n",
    "trainset = CIFAR10('./', download=True, train=True,\n",
    "                   transform=ToTensor())  # LoaderSmall(imageid_path_dict, labels, train=True, transform=tfms, color_space=None)\n",
    "# LoaderSmall(imageid_path_dict, labels, train=True, transform=tfms, color_space=None)\n",
    "# #CIFAR10('./', download=True, train=True, transform=ToTensor())#\n",
    "testset = CIFAR10('./', train=False,\n",
    "                  transform=ToTensor())  # LoaderSmall(imageid_path_dict, labels, train=False, transform=tfms, color_space=None)\n",
    "# LoaderSmall(imageid_path_dict, labels, train=False, transform=tfms, color_space=None)\n",
    "# CIFAR10('./', train=False, transform=ToTensor())#\n",
    "'''\n",
    "train_sampler = torch.utils\\\n",
    "    .data.WeightedRandomSampler(trainset.weights[trainset.train_labels],\n",
    "                                len(trainset.weights[trainset.train_labels]),\n",
    "                                True)\n",
    "test_sampler = torch.utils\\\n",
    "    .data.WeightedRandomSampler(testset.weights[testset.test_labels],\n",
    "                                len(testset.weights[testset.test_labels]),\n",
    "                                True)\n",
    "'''\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          # sampler=train_sampler,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         # sampler=test_sampler,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=0)\n",
    "gc.collect()\n",
    "\n",
    "net =  WideHarmonicResNet(3,28,widen_factor=10)\n",
    "\n",
    "for module in net.modules():\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        module.weight.data.normal_(0, 0.05)\n",
    "        if module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "net = net.to('cuda')\n",
    "for parameter in net.parameters():\n",
    "    parameter.to('cuda')\n",
    "net.cuda()\n",
    "net = torch.nn.DataParallel(\n",
    "    net, device_ids=range(torch.cuda.device_count()))\n",
    "base_lr = 0.1\n",
    "param_dict = dict(net.named_parameters())\n",
    "params = []  # type: List\n",
    "train_losses = []  # type: List[float]\n",
    "test_losses = []  # type: List[float]\n",
    "train_accs = []  # type: List[float]\n",
    "test_accs = []  # type: List[float]\n",
    "train_precisions = []  # type: List[float]\n",
    "test_precisions = []  # type: List[float]\n",
    "train_f1 = []  # type: List[float]\n",
    "test_f1 = []  # type: List[float]\n",
    "train_recall = []  # type: List[float]\n",
    "test_recall = []  # type: List[float]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # BCEWithLogitsLoss()\n",
    "# BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.SGD(params=net.parameters(),\n",
    "                      lr=base_lr,\n",
    "                      momentum=0.9,\n",
    "                      dampening=0,\n",
    "                      weight_decay=0.0005)  # Adam(model_harmonic.parameters(),\n",
    "#     lr=base_lr,\n",
    "#     weight_decay=1e-3)\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "def one_hot_enc(output, target, num_classes=7):\n",
    "    labels = target.view((-1, 1))\n",
    "    batch_size, _ = labels.size()\n",
    "    labels_one_hot = torch.FloatTensor(\n",
    "        batch_size, num_classes).zero_().to('cuda')\n",
    "    labels_one_hot.scatter_(1, labels, 1)\n",
    "    return labels_one_hot\n",
    "\n",
    "\n",
    "def train(epoch, model):\n",
    "    model.train()\n",
    "    corrects = 0.0\n",
    "    f1 = 0.0\n",
    "    prec = 0.0\n",
    "    rec = 0.0\n",
    "    iteration = 0\n",
    "    acc = 0.\n",
    "    for batch_idx, (data, label) in enumerate(tqdm(trainloader)):\n",
    "        data, label = torch.autograd.Variable(\n",
    "            data.cuda()), torch.autograd.Variable(label.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #label_ = one_hot_enc(output, label, 10)\n",
    "        loss = criterion(output, label)\n",
    "        y_pred = torch.max(output, 1)[1]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        corrects += y_pred.eq(label.data).cpu().sum()\n",
    "        f1 += f1_score(y_true=label.data.cpu().numpy(),\n",
    "                       y_pred=y_pred.cpu().numpy(),\n",
    "                       average='weighted')\n",
    "        prec += precision_score(y_true=label.data.cpu().numpy(),\n",
    "                                y_pred=y_pred.cpu().numpy(),\n",
    "                                average='weighted')\n",
    "        rec += recall_score(y_true=label.data.cpu().numpy(),\n",
    "                            y_pred=y_pred.cpu().numpy(),\n",
    "                            average='weighted')\n",
    "        iteration += 1\n",
    "        # t.update(batch_idx)\n",
    "    acc = 100. * corrects / len(trainloader.dataset)\n",
    "    f1 = f1 / iteration\n",
    "    prec = prec / iteration\n",
    "    rec = rec / iteration\n",
    "    train_losses.append(loss.data.item())\n",
    "    train_accs.append(acc)\n",
    "    train_precisions.append(100. * rec)\n",
    "    train_recall.append(100. * rec)\n",
    "    train_f1.append(100. * f1)\n",
    "    print(f\"\\nTraining accuracy = {acc:.2f}%;\\n\\\n",
    "             F1 = {100. * f1:.2f}%;\\\n",
    "             Precision = {100. * prec:.2f}%;\\\n",
    "             Recall = {100. * rec:.2f}%\\\n",
    "             Loss: {loss.data.item():1.2e}\\n\")\n",
    "\n",
    "    # t.close()\n",
    "\n",
    "\n",
    "def test(epoch, model):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    # w = testloader.dataset.weights\n",
    "    acc = 0.0\n",
    "    f1 = 0.0\n",
    "    prec = 0.0\n",
    "    rec = 0.0\n",
    "    iteration = 0\n",
    "    testloss = 0.0\n",
    "    corrects = 0.0\n",
    "    # criterion.weight = torch.from_numpy(testset.weights)\\\n",
    "    # .to('cuda').type(torch.float)\n",
    "    # t = tqdm(total=len(testloader))\n",
    "    for batch_id, (data, label) in enumerate(tqdm(testloader)):\n",
    "        with torch.no_grad():\n",
    "            data, label = torch.autograd.Variable(\n",
    "                data).cuda(), torch.autograd.Variable(label).cuda()\n",
    "            output = model(data)\n",
    "            # one_hot_enc(output, label) # one hot encoding for loss function\n",
    "            #label_ = one_hot_enc(output, label, 10)\n",
    "            loss = criterion(output, label)\n",
    "            y_pred = torch.max(output, 1)[1]\n",
    "            corrects += y_pred.eq(label.data).cpu().sum()\n",
    "            testloss += loss\n",
    "            f1 += f1_score(y_true=label.data.cpu().numpy(),\n",
    "                           y_pred=y_pred.cpu().numpy(),\n",
    "                           average='weighted')\n",
    "            prec += precision_score(y_true=label.data.cpu().numpy(),\n",
    "                                    y_pred=y_pred.cpu().numpy(),\n",
    "                                    average='weighted')\n",
    "            rec += recall_score(y_true=label.data.cpu().numpy(),\n",
    "                                y_pred=y_pred.cpu().numpy(),\n",
    "                                average='weighted')\n",
    "        iteration += 1\n",
    "        # t.update(batch_id)\n",
    "    acc = 100. * corrects / len(testloader.dataset)\n",
    "    f1 = f1 / iteration\n",
    "    prec = prec / iteration\n",
    "    rec = rec / iteration\n",
    "    testloss /= len(testloader.dataset)\n",
    "    if best_acc < acc.item():\n",
    "        best_acc = acc\n",
    "        save_state(model, best_acc)\n",
    "    print(\n",
    "        f\"\\nTesting accuracy = {acc:.2f}%; \\n \\\n",
    "            F1 = {100. * f1:.2f}%; \\\n",
    "            Precision = {100. * prec:.2f}%;\\\n",
    "            Recall = {100. * rec:.2f}% \\\n",
    "            Loss: {loss.data.item():1.2e}\\n\")\n",
    "    test_losses.append(loss.data.item())\n",
    "    test_accs.append(acc)\n",
    "    test_precisions.append(100. * rec)\n",
    "    test_recall.append(100. * rec)\n",
    "    test_f1.append(100. * f1)\n",
    "    # t.close()\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer,\n",
    "                         epoch,\n",
    "                         update_list=[25, 75],\n",
    "                         factor=10,\n",
    "                         lim = 1.):\n",
    "    # [60, 120, 160]  #[2,5,8,11,14,17,20]\n",
    "    if epoch in update_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = min(param_group['lr'] * factor, lim)\n",
    "    return\n",
    "\n",
    "\n",
    "def save_state(model, best_acc):\n",
    "    print('\\n==> Saving model ...\\n')\n",
    "    state = {'best_acc': best_acc,\n",
    "             'state_dict': model.state_dict()}\n",
    "    keys = list(state['state_dict'].keys())\n",
    "    for key in keys:\n",
    "        if 'module' in key:\n",
    "            state['state_dict'][key.replace('module.', '')] = \\\n",
    "                state['state_dict'].pop(key)\n",
    "    torch.save(state, 'harmonic_network.tar')\n",
    "\n",
    "\n",
    "def get_lr(optimizer=optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "# t = tqdm(total=300)\n",
    "for epoch in range(200):\n",
    "    adjust_learning_rate(optimizer, epoch, [60,120,160],factor=0.2, lim=1e-4)\n",
    "    lr = get_lr()\n",
    "    print(f\" Epoch: {epoch}, learning rate = {lr:1.1e};\\n\")\n",
    "    train(epoch, net)\n",
    "    test(epoch, net)\n",
    "    gc.collect()\n",
    "    if np.nan in test_losses or np.nan in train_losses:\n",
    "        break\n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "exploration_notebook2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
